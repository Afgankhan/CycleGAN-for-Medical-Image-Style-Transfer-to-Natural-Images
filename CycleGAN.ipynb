{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Afgankhan/CycleGAN-for-Medical-Image-Style-Transfer-to-Natural-Images/blob/main/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2X9T8RnuH0G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class ConvolutionalBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        is_downsampling: bool = True,\n",
        "        add_activation: bool = True,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__()\n",
        "        if is_downsampling:\n",
        "            self.conv = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs),\n",
        "                nn.InstanceNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True) if add_activation else nn.Identity(),\n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
        "                nn.InstanceNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True) if add_activation else nn.Identity(),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n-clMqzugu1"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels: int):\n",
        "        \"\"\"\n",
        "        In a residual block, the use of two ConvBlock instances with one having\n",
        "        an activation function and the other not is a design choice that promotes\n",
        "        the learning of residual information.\n",
        "\n",
        "        The purpose of a residual block is to learn the residual mapping between\n",
        "        the input and output of the block. The first ConvBlock in the sequence,\n",
        "        which includes an activation function, helps in capturing and extracting\n",
        "        important features from the input. The activation function introduces\n",
        "        non-linearity, allowing the network to model complex relationships\n",
        "        between the input and output.\n",
        "\n",
        "        The second ConvBlock does not include an activation function.\n",
        "        It mainly focuses on adjusting the dimensions (e.g., number of channels)\n",
        "        of the features extracted by the first ConvBlock. The absence of an\n",
        "        activation function in the second ConvBlock allows the block to learn\n",
        "        the residual information. By directly adding the output of the second\n",
        "        ConvBlock to the original input, the block learns to capture the\n",
        "        residual features or changes needed to reach the desired output.\n",
        "\n",
        "        (Information and explanation above generated by ChatGPT)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            ConvolutionalBlock(channels, channels, add_activation=True, kernel_size=3, padding=1),\n",
        "            ConvolutionalBlock(channels, channels, add_activation=False, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        This skip connection, achieved through the addition operation, helps\n",
        "        in propagating gradients during training and alleviates the vanishing\n",
        "        gradient problem. It also facilitates the flow of information from earlier\n",
        "        layers to later layers, allowing the network to learn more effectively.\n",
        "\n",
        "        (Information and explanation above generated by ChatGPT)\n",
        "        \"\"\"\n",
        "        return x + self.block(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ_7SHoBHvvj"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(\n",
        "        self, img_channels: int, num_features: int = 64, num_residuals: int = 9\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Generator consists of 2 layers of downsampling/encoding layer,\n",
        "        followed by 9 residual blocks for 128 × 128 training images\n",
        "        and then 3 upsampling/decoding layer.\n",
        "\n",
        "        The network with 6 residual blocks can be written as:\n",
        "        c7s1–64, d128, d256, R256, R256, R256, R256, R256, R256, u128, u64, and c7s1–3.\n",
        "\n",
        "        The network with 9 residual blocks consists of:\n",
        "        c7s1–64, d128, d256, R256, R256, R256, R256, R256, R256, R256, R256, R256, u128, u64, and c7s1–3.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.initial_layer = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                img_channels,\n",
        "                num_features,\n",
        "                kernel_size=7,\n",
        "                stride=1,\n",
        "                padding=3,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.downsampling_layers = nn.ModuleList(\n",
        "            [\n",
        "                ConvolutionalBlock(\n",
        "                    num_features,\n",
        "                    num_features * 2,\n",
        "                    is_downsampling=True,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                ),\n",
        "                ConvolutionalBlock(\n",
        "                    num_features * 2,\n",
        "                    num_features * 4,\n",
        "                    is_downsampling=True,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.residual_layers = nn.Sequential(\n",
        "            *[ResidualBlock(num_features * 4) for _ in range(num_residuals)]\n",
        "        )\n",
        "\n",
        "        self.upsampling_layers = nn.ModuleList(\n",
        "            [\n",
        "                ConvolutionalBlock(\n",
        "                    num_features * 4,\n",
        "                    num_features * 2,\n",
        "                    is_downsampling=False,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                    output_padding=1,\n",
        "                ),\n",
        "                ConvolutionalBlock(\n",
        "                    num_features * 2,\n",
        "                    num_features * 1,\n",
        "                    is_downsampling=False,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                    output_padding=1,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.last_layer = nn.Conv2d(\n",
        "            num_features * 1,\n",
        "            img_channels,\n",
        "            kernel_size=7,\n",
        "            stride=1,\n",
        "            padding=3,\n",
        "            padding_mode=\"reflect\",\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial_layer(x)\n",
        "        for layer in self.downsampling_layers:\n",
        "            x = layer(x)\n",
        "        x = self.residual_layers(x)\n",
        "        for layer in self.upsampling_layers:\n",
        "            x = layer(x)\n",
        "        return torch.tanh(self.last_layer(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52ah29y8Xis_"
      },
      "outputs": [],
      "source": [
        "class ConvInstanceNormLeakyReLUBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, stride: int):\n",
        "        \"\"\"\n",
        "        Class object initialization for Convolution-InstanceNorm-LeakyReLU layer\n",
        "\n",
        "        We use leaky ReLUs with a slope of 0.2.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                kernel_size=4,\n",
        "                stride=stride,\n",
        "                padding=1,\n",
        "                bias=True,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etOeQGp1mMw5"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
        "        \"\"\"\n",
        "        Let Ck denote a 4 × 4 Convolution-InstanceNorm-LeakyReLU layer with\n",
        "        k filters and stride 2. Discriminator architecture is: C64-C128-C256-C512.\n",
        "\n",
        "        After the last layer, we apply a convolution to produce a 1-dimensional\n",
        "        output.\n",
        "\n",
        "        We use leaky ReLUs with a slope of 0.2.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.initial_layer = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                features[0],\n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            layers.append(\n",
        "                ConvInstanceNormLeakyReLUBlock(\n",
        "                    in_channels,\n",
        "                    feature,\n",
        "                    stride=1 if feature == features[-1] else 2,\n",
        "                )\n",
        "            )\n",
        "            in_channels = feature\n",
        "\n",
        "        # After the last layer, we apply a convolution to produce a 1-dimensional output\n",
        "        layers.append(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                1,\n",
        "                kernel_size=4,\n",
        "                stride=1,\n",
        "                padding=1,\n",
        "                padding_mode=\"reflect\",\n",
        "            )\n",
        "        )\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial_layer(x)\n",
        "\n",
        "        # feed the model output into a sigmoid function to make a 1/0 label\n",
        "        return torch.sigmoid(self.model(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CMpDxEcmRoC"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class HorseZebraDataset(Dataset):\n",
        "    def __init__(self, root_zebra, root_horse, transform=None):\n",
        "        self.root_zebra = root_zebra\n",
        "        self.root_horse = root_horse\n",
        "        self.transform = transform\n",
        "\n",
        "        self.zebra_images = os.listdir(root_zebra)\n",
        "        self.horse_images = os.listdir(root_horse)\n",
        "        self.length_dataset = max(len(self.zebra_images), len(self.horse_images))\n",
        "        self.zebra_len = len(self.zebra_images)\n",
        "        self.horse_len = len(self.horse_images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        zebra_img = self.zebra_images[index % self.zebra_len]\n",
        "        horse_img = self.horse_images[index % self.horse_len]\n",
        "\n",
        "        zebra_path = os.path.join(self.root_zebra, zebra_img)\n",
        "        horse_path = os.path.join(self.root_horse, horse_img)\n",
        "\n",
        "        zebra_img = np.array(Image.open(zebra_path).convert(\"RGB\"))\n",
        "        horse_img = np.array(Image.open(horse_path).convert(\"RGB\"))\n",
        "\n",
        "        if self.transform:\n",
        "            augmentations = self.transform(image=zebra_img, image0=horse_img)\n",
        "            zebra_img = augmentations[\"image\"]\n",
        "            horse_img = augmentations[\"image0\"]\n",
        "\n",
        "        return zebra_img, horse_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRdyqIXItJ4z",
        "outputId": "c8da7c3b-dfb4-412b-dd33-88f82e902db4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/AI/CycleGAN\n",
            " CycleGAN.ipynb  'CycleGAN paper.pdf'   data   models   outputs\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/My Drive/AI/CycleGAN\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWqoRijtmm6n",
        "outputId": "37af6a13-8ade-4441-c2a9-97aefa578ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"using device: {DEVICE}\")\n",
        "\n",
        "TRAIN_DIR = \"data/train\"\n",
        "VAL_DIR = \"data/val\"\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 1e-5\n",
        "LAMBDA_IDENTITY = 0.0 # loss weight for identity loss\n",
        "LAMBDA_CYCLE = 10\n",
        "NUM_WORKERS = 4\n",
        "NUM_EPOCHS = 50\n",
        "LOAD_MODEL = True\n",
        "SAVE_MODEL = True\n",
        "CHECKPOINT_GENERATOR_H = \"models/genh.pth.tar\"\n",
        "CHECKPOINT_GENERATOR_Z = \"models/genz.pth.tar\"\n",
        "CHECKPOINT_DISCRIMINATOR_H = \"models/disch.pth.tar\"\n",
        "CHECKPOINT_DISCRIMINATOR_Z = \"models/discz.pth.tar\"\n",
        "\n",
        "transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=256, height=256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    additional_targets={\"image0\": \"image\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohRGVCIDme9v"
      },
      "outputs": [],
      "source": [
        "import random, torch, os, numpy as np\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "\n",
        "def save_checkpoint(model, optimizer, filename=\"models/checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTX6zq8RmfWN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "def train_fn(\n",
        "    disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler\n",
        "):\n",
        "    H_reals = 0\n",
        "    H_fakes = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (zebra, horse) in enumerate(loop):\n",
        "        zebra = zebra.to(DEVICE)\n",
        "        horse = horse.to(DEVICE)\n",
        "\n",
        "        # Train discriminators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_horse = gen_H(zebra)\n",
        "            D_H_real = disc_H(horse)\n",
        "            D_H_fake = disc_H(fake_horse.detach())\n",
        "            H_reals += D_H_real.mean().item()\n",
        "            H_fakes += D_H_fake.mean().item()\n",
        "            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n",
        "            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n",
        "            D_H_loss = D_H_real_loss + D_H_fake_loss\n",
        "\n",
        "            fake_zebra = gen_Z(horse)\n",
        "            D_Z_real = disc_Z(zebra)\n",
        "            D_Z_fake = disc_Z(fake_zebra.detach())\n",
        "            D_Z_real_loss = mse(D_Z_real, torch.ones_like(D_Z_real))\n",
        "            D_Z_fake_loss = mse(D_Z_fake, torch.zeros_like(D_Z_fake))\n",
        "            D_Z_loss = D_Z_real_loss + D_Z_fake_loss\n",
        "\n",
        "            D_loss = (D_H_loss + D_Z_loss) / 2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train generators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # adversarial losses\n",
        "            D_H_fake = disc_H(fake_horse)\n",
        "            D_Z_fake = disc_Z(fake_zebra)\n",
        "            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n",
        "            loss_G_Z = mse(D_Z_fake, torch.ones_like(D_Z_fake))\n",
        "\n",
        "            # cycle losses\n",
        "            cycle_zebra = gen_Z(fake_horse)\n",
        "            cycle_horse = gen_H(fake_zebra)\n",
        "            cycle_zebra_loss = l1(zebra, cycle_zebra)\n",
        "            cycle_horse_loss = l1(horse, cycle_horse)\n",
        "\n",
        "            # identity losses\n",
        "            # identity_zebra = gen_Z(zebra)\n",
        "            # identity_horse = gen_H(horse)\n",
        "            # identity_zebra_loss = l1(zebra, identity_zebra)\n",
        "            # identity_horse_loss = l1(horse, identity_horse)\n",
        "\n",
        "            # total loss\n",
        "            G_loss = (\n",
        "                loss_G_Z\n",
        "                + loss_G_H\n",
        "                + cycle_zebra_loss * LAMBDA_CYCLE\n",
        "                + cycle_horse_loss * LAMBDA_CYCLE\n",
        "                # + identity_horse_loss * LAMBDA_IDENTITY\n",
        "                # + identity_zebra_loss * LAMBDA_IDENTITY\n",
        "            )\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        if idx % 200 == 0:\n",
        "            save_image(fake_horse * 0.5 + 0.5, f\"outputs/horse_{idx}.png\")\n",
        "            save_image(fake_zebra * 0.5 + 0.5, f\"outputs/zebra_{idx}.png\")\n",
        "\n",
        "        loop.set_postfix(H_real=H_reals / (idx + 1), H_fake=H_fakes / (idx + 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKo2Ne5TkBzW",
        "outputId": "782e1cf2-00c7-437a-aed6-cbea078fabe8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Loading checkpoint\n",
            "=> Loading checkpoint\n",
            "=> Loading checkpoint\n",
            "=> Loading checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|██████████| 1344/1344 [04:38<00:00,  4.82it/s, H_fake=0.383, H_real=0.612]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:09<00:00,  5.39it/s, H_fake=0.384, H_real=0.614]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:09<00:00,  5.39it/s, H_fake=0.382, H_real=0.613]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:09<00:00,  5.38it/s, H_fake=0.383, H_real=0.613]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:08<00:00,  5.40it/s, H_fake=0.383, H_real=0.615]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:08<00:00,  5.41it/s, H_fake=0.383, H_real=0.614]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:08<00:00,  5.41it/s, H_fake=0.383, H_real=0.612]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:10<00:00,  5.37it/s, H_fake=0.383, H_real=0.613]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:09<00:00,  5.38it/s, H_fake=0.384, H_real=0.613]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:09<00:00,  5.38it/s, H_fake=0.383, H_real=0.613]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:09<00:00,  5.39it/s, H_fake=0.383, H_real=0.614]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:09<00:00,  5.40it/s, H_fake=0.383, H_real=0.614]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:10<00:00,  5.37it/s, H_fake=0.383, H_real=0.614]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:10<00:00,  5.37it/s, H_fake=0.381, H_real=0.614]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:09<00:00,  5.38it/s, H_fake=0.382, H_real=0.614]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:09<00:00,  5.39it/s, H_fake=0.381, H_real=0.614]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:09<00:00,  5.38it/s, H_fake=0.383, H_real=0.614]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:09<00:00,  5.38it/s, H_fake=0.382, H_real=0.614]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:08<00:00,  5.40it/s, H_fake=0.382, H_real=0.614]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:08<00:00,  5.41it/s, H_fake=0.382, H_real=0.614]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:06<00:00,  5.44it/s, H_fake=0.382, H_real=0.615]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:07<00:00,  5.44it/s, H_fake=0.381, H_real=0.615]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1344/1344 [04:07<00:00,  5.44it/s, H_fake=0.381, H_real=0.615]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 173/1344 [00:33<03:28,  5.60it/s, H_fake=0.381, H_real=0.613]"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    disc_H = Discriminator(in_channels=3).to(DEVICE)\n",
        "    disc_Z = Discriminator(in_channels=3).to(DEVICE)\n",
        "    gen_Z = Generator(img_channels=3, num_residuals=9).to(DEVICE)\n",
        "    gen_H = Generator(img_channels=3, num_residuals=9).to(DEVICE)\n",
        "\n",
        "    # use Adam Optimizer for both generator and discriminator\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_H.parameters()) + list(disc_Z.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_Z.parameters()) + list(gen_H.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GENERATOR_H,\n",
        "            gen_H,\n",
        "            opt_gen,\n",
        "            LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GENERATOR_Z,\n",
        "            gen_Z,\n",
        "            opt_gen,\n",
        "            LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_DISCRIMINATOR_H,\n",
        "            disc_H,\n",
        "            opt_disc,\n",
        "            LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_DISCRIMINATOR_Z,\n",
        "            disc_Z,\n",
        "            opt_disc,\n",
        "            LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "    dataset = HorseZebraDataset(\n",
        "        root_horse=TRAIN_DIR + \"/horses\",\n",
        "        root_zebra=TRAIN_DIR + \"/zebras\",\n",
        "        transform=transforms,\n",
        "    )\n",
        "    val_dataset = HorseZebraDataset(\n",
        "        root_horse=VAL_DIR + \"/horses\",\n",
        "        root_zebra=VAL_DIR + \"/zebras\",\n",
        "        transform=transforms,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_fn(\n",
        "            disc_H,\n",
        "            disc_Z,\n",
        "            gen_Z,\n",
        "            gen_H,\n",
        "            loader,\n",
        "            opt_disc,\n",
        "            opt_gen,\n",
        "            L1,\n",
        "            mse,\n",
        "            d_scaler,\n",
        "            g_scaler,\n",
        "        )\n",
        "\n",
        "        if SAVE_MODEL:\n",
        "            save_checkpoint(gen_H, opt_gen, filename=CHECKPOINT_GENERATOR_H)\n",
        "            save_checkpoint(gen_Z, opt_gen, filename=CHECKPOINT_GENERATOR_Z)\n",
        "            save_checkpoint(disc_H, opt_disc, filename=CHECKPOINT_DISCRIMINATOR_H)\n",
        "            save_checkpoint(disc_Z, opt_disc, filename=CHECKPOINT_DISCRIMINATOR_Z)\n",
        "\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrE_eiBpkFIj"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}